{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO remove\n",
    "#interesting code:\n",
    "#: https://github.com/reeanne/FinalProject/blob/cef6b45060ad9646f2be4de93c226aebeadec41b/essentia-master/src/examples/python/streaming_extractor/tonaldescriptors.py\n",
    "#https://github.com/LqNoob/Essentia/blob/7a70a25dd6668855b3677bd0cae0df190e319cbf/test/src/unittest/tonal/test_chordsdetection_streaming.py\n",
    "#âˆ«imple one https://github.com/mariogearth/ChordsDetectionPython/blob/b69e813bef92a361e7cad0a58bbd0f049b252914/old%20stuff/chords_test3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at TODOs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "%matplotlib inline\n",
    "\n",
    "import essentia, essentia.standard, essentia.streaming\n",
    "import essentia.standard as ess\n",
    "from essentia.standard import BeatTrackerMultiFeature\n",
    "from essentia.standard import ChordsDetectionBeats\n",
    "from essentia.streaming import *\n",
    "\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "UTILS \n",
    "utils, inspired/copied from:\n",
    "  https://github.com/seffka/ACE2017/blob/master/essentia_chord_utils.py\n",
    "\n",
    "'''\n",
    "\n",
    "def tuning(infile):\n",
    "    hopSize = 2048\n",
    "    frameSize = 8192\n",
    "    loader = MonoLoader(filename=infile)\n",
    "    framecutter = FrameCutter(hopSize=hopSize, frameSize=frameSize)\n",
    "    windowing = Windowing(type=\"blackmanharris62\")\n",
    "    spectrum = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"frequency\",\n",
    "                                  magnitudeThreshold=1e-05,\n",
    "                                  minFrequency=40,\n",
    "                                  maxFrequency=5000,\n",
    "                                  maxPeaks=10000)\n",
    "    tuning = TuningFrequency()\n",
    "    # use pool to store data\n",
    "    pool = essentia.Pool()\n",
    "    # connect algorithms together\n",
    "    loader.audio >> framecutter.signal\n",
    "    framecutter.frame >> windowing.frame >> spectrum.frame\n",
    "    spectrum.spectrum >> spectralpeaks.spectrum\n",
    "    spectralpeaks.magnitudes >> tuning.magnitudes\n",
    "    spectralpeaks.frequencies >> tuning.frequencies\n",
    "    tuning.tuningFrequency >> (pool, 'tonal.tuningFrequency')\n",
    "    tuning.tuningCents >> (pool, 'tonal.tuningCents')\n",
    "    # network is ready, run it\n",
    "    print ('Processing audio file...', infile)\n",
    "    essentia.run(loader)\n",
    "    return np.average(pool['tonal.tuningFrequency'])\n",
    "\n",
    "class ChordSegment :\n",
    "    startTime = 0.0\n",
    "    endTime = 0.0\n",
    "    symbol = ''\n",
    "    def __init__(self, startTime, endTime, symbol):\n",
    "        self.startTime = startTime\n",
    "        self.endTime = endTime\n",
    "        self.symbol = symbol\n",
    "    def __repr__(self):\n",
    "        return str(self.startTime) + '\\t' + str(self.endTime) + '\\t' + self.symbol\n",
    "    \n",
    "def mergeSegments(chordSegments) :\n",
    "    if (len(chordSegments) < 2) :\n",
    "        return chordSegments\n",
    "    res = []\n",
    "    currentSegment = chordSegments[0]\n",
    "    for segment in chordSegments[1:] :\n",
    "        if (segment.symbol == currentSegment.symbol):\n",
    "            currentSegment.endTime = segment.endTime\n",
    "        else:\n",
    "            res.append(currentSegment)\n",
    "            currentSegment = segment\n",
    "    res.append(currentSegment)\n",
    "    return res\n",
    "\n",
    "def convertChordLabels(chordSegments) :\n",
    "    for segment in chordSegments :\n",
    "        segment.symbol = re.sub('m$', ':min', segment.symbol)\n",
    "    return chordSegments\n",
    "\n",
    "\n",
    "def toMirexLab(startTime, endTime, onsets, symbols, strengths) :\n",
    "    if (len(onsets) < len(symbols) or len(symbols) != len(strengths)) :\n",
    "        raise ValueError(\"inappropriate lists lengths\")\n",
    "    if (len(onsets) == len(symbols)) :\n",
    "        onsets = np.concatenate((onsets, [endTime]))\n",
    "    res = []\n",
    "    if (startTime < onsets[0]) :\n",
    "        res.append(ChordSegment(startTime, onsets[0], 'N'))\n",
    "    for i in range(len(symbols)) :\n",
    "        sym = symbols[i] if strengths[i] > 0 else 'N'\n",
    "        res.append(ChordSegment(onsets[i], onsets[i+1], sym))\n",
    "    if (res[-1].endTime < endTime) :\n",
    "        res.append(ChordSegment(res[-1].endTime, endTime, 'N'))\n",
    "    return convertChordLabels(mergeSegments(res))\n",
    "\n",
    "\n",
    "def processFiles(inputDir, outputDir, processFunction) :\n",
    "    for file in [f for f in os.listdir(inputDir) if os.path.isfile(os.path.join(inputDir, f))] :\n",
    "        name, ext = os.path.splitext(file)\n",
    "        processFunction(os.path.join(inputDir, file), os.path.join(outputDir, name + '.lab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute Chords by Frames in Essentia \n",
    "utils, inspired/copied from:\n",
    "  https://github.com/seffka/ACE2017/blob/master/essentia_chord_utils.py\n",
    "\n",
    "'''\n",
    "\n",
    "def computeChordsByFrames(filename, outfile, frameSize=4096, hopSize=2048, tuningFrequency=440.0):\n",
    "\n",
    "    #TODO:check pools https://essentia.upf.edu/documentation/essentia_python_tutorial.html \n",
    "\n",
    "    pool = essentia.Pool()\n",
    "    loader = essentia.streaming.MonoLoader(filename=filename)\n",
    "    \n",
    "    #get the frames and compute chord detection\n",
    "    fc = FrameCutter(frameSize=frameSize,\n",
    "                     hopSize=hopSize,\n",
    "                     silentFrames='noise')\n",
    "\n",
    "    w = Windowing(type='blackmanharris62')\n",
    "    spec = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"magnitude\",\n",
    "                                      magnitudeThreshold=1e-05,\n",
    "                                      minFrequency=40,\n",
    "                                      maxFrequency=5000,\n",
    "                                      maxPeaks=10000)\n",
    "    \n",
    "    #TODO learn: https://essentia.upf.edu/documentation/reference/std_HPCP.html\n",
    "    hpcp = HPCP(\n",
    "        size=12,\n",
    "        referenceFrequency = tuningFrequency,\n",
    "        harmonics = 8,\n",
    "        bandPreset = True,\n",
    "        minFrequency = 40.0,\n",
    "        maxFrequency = 5000.0,\n",
    "        bandSplitFrequency = 250.0,\n",
    "        weightType = \"cosine\",\n",
    "        nonLinear = False,\n",
    "        windowSize = 1.0,\n",
    "        normalized='unitMax')\n",
    "    \n",
    "    #TODO: check parameters https://essentia.upf.edu/documentation/reference/std_ChordsDetection.html\n",
    "    chords = ChordsDetection()\n",
    "    chords_desc = ChordsDescriptors()\n",
    "\n",
    "\n",
    "    # connect algorithms together\n",
    "    loader.audio >> fc.signal\n",
    "    fc.frame >> w.frame >> spec.frame\n",
    "    spec.spectrum >> spectralpeaks.spectrum\n",
    "    spec.spectrum >> (pool, 'spectrum.magnitude') #mine\n",
    "    spectralpeaks.frequencies >> hpcp.frequencies\n",
    "    spectralpeaks.magnitudes >> hpcp.magnitudes\n",
    "    hpcp.hpcp >> (pool, 'chroma.hpcp')  #mine\n",
    "    hpcp.hpcp >> chords.pcp\n",
    "    chords.chords >> (pool, 'chords.chords')\n",
    "    chords.strength >> (pool, 'chords.strength')\n",
    "\n",
    "    essentia.run(loader)\n",
    "\n",
    "\n",
    "    audio = essentia.standard.MonoLoader(filename = filename)()\n",
    "    endTime = len(audio) / 44100.0\n",
    "    stamps = np.arange(0, endTime, float(hopSize/44100.0))\n",
    "    stamps = np.array([round(stamp,2) for stamp in stamps]) #2 decimals\n",
    "\n",
    "    # workaround for Essentia behaviour I don't quite undestand: https://github.com/seffka/ACE2017/blob/467068d9667de43de8b8b8396e620d9e62a0d85c/essentia_chords.py\n",
    "    syms = list(pool['chords.chords'][:-1])\n",
    "    strengths = list(pool['chords.strength'][:-1])\n",
    "    segments = toMirexLab(0.0, endTime, stamps, syms, strengths)\n",
    "    with open(outfile, 'w') as content_file:\n",
    "        for s in segments:\n",
    "            content_file.write(str(s) + '\\n')\n",
    "    print(\"\\n\", outfile, \" was written\")\n",
    "\n",
    "    \n",
    "    spectrum= pool['spectrum.magnitude']\n",
    "    chroma= pool['chroma.hpcp']\n",
    "    chords= pool['chords.chords']\n",
    "    chords_strength= pool['chords.strength']\n",
    "    \n",
    "    return spectrum, chroma, chords, chords_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeChordsByBeats(filename, outfile, hopSize=4096, frameSize=8192, tuningFrequency=440.0):\n",
    "    \n",
    "    # use pool to store data\n",
    "    pool = essentia.Pool()\n",
    "    # initialize algorithms we will use\n",
    "    loader = MonoLoader(filename=filename)\n",
    "    framecutter = FrameCutter(hopSize=hopSize, frameSize=frameSize)\n",
    "    windowing = Windowing(type=\"blackmanharris62\")\n",
    "    spectrum = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"magnitude\",\n",
    "                                  magnitudeThreshold=1e-05,\n",
    "                                  minFrequency=40,\n",
    "                                  maxFrequency=5000,\n",
    "                                  maxPeaks=10000)\n",
    "    hpcp = HPCP(size=12,\n",
    "                referenceFrequency = tuningFrequency,\n",
    "                harmonics = 8,\n",
    "                bandPreset = True,\n",
    "                minFrequency = 40.0,\n",
    "                maxFrequency = 5000.0,\n",
    "                bandSplitFrequency = 500.0,\n",
    "                weightType = \"cosine\",\n",
    "                nonLinear = True,\n",
    "                windowSize = 1.0)\n",
    "\n",
    "    # connect algorithms together\n",
    "    loader.audio >> framecutter.signal\n",
    "    framecutter.frame >> windowing.frame >> spectrum.frame\n",
    "    spectrum.spectrum >> spectralpeaks.spectrum\n",
    "    spectralpeaks.magnitudes >> hpcp.magnitudes\n",
    "    spectralpeaks.frequencies >> hpcp.frequencies\n",
    "    hpcp.hpcp >> (pool, 'chroma.hpcp')\n",
    "\n",
    "    essentia.run(loader)\n",
    "    \n",
    "    print('Loading audio file...', filename)\n",
    "    audio = ess.MonoLoader(filename = filename)()\n",
    "    bt = ess.BeatTrackerMultiFeature()\n",
    "    beats, confidence = bt(audio)\n",
    "    beats = np.array([round(beat,2) for beat in beats])\n",
    "    \n",
    "    #ticks = beats[::4] # TODO: should we take each 4 beats??\n",
    "    print(\"number of beats\", len(beats))\n",
    "\n",
    "    computeChordsByBeats = ChordsDetectionBeats(hopSize=hopSize)\n",
    "    chords, strengths = computeChordsByBeats(pool['chroma.hpcp'], beats)\n",
    "    \n",
    "    segments = toMirexLab(0.0, len(audio) / 44100.0, beats, chords, strengths)\n",
    "    with open(outfile, 'w') as content_file:\n",
    "        for s in segments:\n",
    "            content_file.write(str(s) + '\\n')\n",
    "    print(\"\\n\", outfile, \" was written\")\n",
    "    \n",
    "    \n",
    "    return chords, strengths, beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTriads(estimate_file, reference_file):\n",
    "    '''\n",
    "    expects .lab files\n",
    "    performs mir_eval on triads\n",
    "    return an object with '''\n",
    "    (ref_intervals, ref_labels) = mir_eval.io.load_labeled_intervals(reference_file)\n",
    "    (est_intervals, est_labels) = mir_eval.io.load_labeled_intervals(estimate_file)\n",
    "\n",
    "    est_intervals, est_labels = mir_eval.util.adjust_intervals(\n",
    "        est_intervals, est_labels, ref_intervals.min(),\n",
    "        ref_intervals.max(), mir_eval.chord.NO_CHORD,\n",
    "        mir_eval.chord.NO_CHORD)\n",
    "\n",
    "    (intervals,\n",
    "     ref_labels,\n",
    "     est_labels) = mir_eval.util.merge_labeled_intervals(\n",
    "        ref_intervals, ref_labels, est_intervals, est_labels)\n",
    "\n",
    "    durations = mir_eval.util.intervals_to_durations(intervals)\n",
    "    comparisons = mir_eval.chord.triads(ref_labels, est_labels)\n",
    "    score = mir_eval.chord.weighted_accuracy(comparisons, durations)\n",
    "    \n",
    "    #create a result object and save all that might be handy\n",
    "    class Object(object):\n",
    "        pass\n",
    "    \n",
    "    result = Object()\n",
    "    result.durations = durations\n",
    "    result.comparisons = comparisons\n",
    "    result.score = score\n",
    "    result.intervals = intervals\n",
    "    result.ref_labels = ref_labels\n",
    "    result.est_labels = est_labels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio file... ./test-audio/Disc 1 - 01 - Maple Leaf Rag.flac\n",
      "Loading audio file... ./test-audio/Disc 1 - 01 - Maple Leaf Rag.flac\n",
      "number of beats 300\n",
      "\n",
      " ./estimated_chordBeat_labs/test2.lab  was written\n",
      "\n",
      " ./estimated_chordFrame_labs/test1.lab  was written\n"
     ]
    }
   ],
   "source": [
    "#evaluate with mir_eval\n",
    "\n",
    "#fake_test = \"./estimated_chordBeat_labs/test_fake.lab\"\n",
    "\n",
    "\n",
    "audiopath = './test-audio/Disc 1 - 01 - Maple Leaf Rag.flac'\n",
    "reference_lab = \"./ref_labs/maple_leaf_rag(hyman).lab\"\n",
    "estimated_chordBeat_lab = \"./estimated_chordBeat_labs/test2.lab\"\n",
    "estimated_chordFrame_lab = './estimated_chordFrame_labs/test1.lab'\n",
    "\n",
    "\n",
    "#create lab files\n",
    "song_tuning = tuning(audiopath)\n",
    "computeChordsByBeats(audiopath, estimated_chordBeat_lab, tuningFrequency=song_tuning)\n",
    "computeChordsByFrames(audiopath, estimated_chordFrame_lab, tuningFrequency=song_tuning)\n",
    "\n",
    "\n",
    "#evaluate chord By Beat\n",
    "beat_mir_eval_result = evaluateTriads(estimated_chordFrame_lab, reference_lab)\n",
    "\n",
    "#evaluate chords By Frame\n",
    "frame_mir_eval_result = evaluateTriads(estimated_chordFrame_lab, reference_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"durations\\n\",len(beat_mir_eval_result.durations), beat_mir_eval_result.durations)\n",
    "print(\"\\n comparisons: \\n\",len(beat_mir_eval_result.comparisons),beat_mir_eval_result.comparisons)\n",
    "print(\"\\n score \\n\",beat_mir_eval_result.score)\n",
    "\n",
    "print(sum(beat_mir_eval_result.comparisons))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITIES = {\n",
    "    #           1     2     3     4  5     6     7\n",
    "    'maj':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'min':     [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'aug':     [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    'dim':     [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    'sus4':    [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "    'sus2':    [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    '7':       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'maj7':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "    'min7':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'minmaj7': [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "    'maj6':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
    "    'min6':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "    'dim7':    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    'hdim7':   [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
    "    'maj9':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "    'min9':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '9':       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'b9':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '#9':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'min11':   [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '11':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '#11':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'maj13':   [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "    'min13':   [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '13':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'b13':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    '1':       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    '5':       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    '':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
